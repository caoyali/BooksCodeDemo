# 自我介绍

# 第一页
各位评委各位领导大家好，我是曹娅丽。
首先我简单的介绍一下自己，毕业于哈尔滨理工大学，软件工程专业科班出身，九零后，巨蟹座，INTJ，平常爱好运动，喜欢打乒乓球，偶尔回去楼下打，在座的各位如果有此爱好的话，兴许我们之前遇见过哈哈哈。另外就是我会偶尔写写技术博客，我的博客主页在PPT下方给出了，欢迎访问。
我是于去年九月份加入我们的团队,是研发二十九组的一名Sdk研发工程师，日常工作主要是负责SDK的开发和维护，以及开发维护我们内部用于测试集成功能的Demo。

很荣幸参加今天晋升答辩，下面是我的晋升理由阐述，
首先是工作产出与价值贡献角度，核心有三部分：

# 翻开第二页：
## 第一点，是Android Sdk 开发与维护
由于我工作中涉及到的范围比较广，涉及的库比较多，对于SDK方面而言,安卓部分由我全权开发维护的主要是, VR 全景SDK, Support Java底层公共库, Zoss,文件上传库, HB IM(IM 融合层), IM 经过不断迭代,目前这个层级已经干掉,部分逻辑已经下沉到适配层中. 然后右边这四个， 是我工作中以参与的角色涉及到的工作，通常是接一些需求实现,其中主要是 IM底层, RTC 底层, Transport 底层传输库 以及 Matrix 美颜相关。这块我不是负责人，但是自己的需求是会改动到这里的。
如本图所示，我们组安卓客户端提供给业务侧所有能力涉及到的实现库，其中每一个方块均代表一种能力库，我把他们分为了三行，由深蓝色，浅蓝色和淡蓝色组成，这些颜色标注，代表了我个人工作当中，对这些能力库代码实现的参与程度。从图中可以看到，我平常的工作，维护的库的数量种类是比较多的，主维护数量约 1/3，所有涉及库维护数量达 2/3。 下面我解释一下对于这些库，我做了什么工作。

VR库是我们的全景拍照，和全景图片预览库，被用在boss直聘公司信息采集和公司详情查看相关的业务中。我们以一个uikit的形式提供给业务方进行使用，目前主要用于公司信息采集，我从年初接手过后先后经历了12次版本迭代，目前我们已经由原生VR，更新到了支持webView版VR两种uikit。后面我将重点讲一下VR相关的案例，在这里不做赘述了就。

Support库是我们各模块java层依赖的一种公共库，里面主要是将各模块都用到的一些能力提炼出来，例如公共的请求库，日志库，检查类， 文件操作等等。 最开始的时候，是为了要解决一个底层的崩溃，打算改进RTC中的http请求，但是我在开发过程中，发现每个模块都各自用各自的类，我在RTC中写完也难以做到复用，于是提出了要不要开一个专门的公共类库，得到了同事们的一致同意，于是就有了这个库。
对于这个库的维护, 我做了：
- 封装可以自维护sig auth的http协议请求类。对sig auth 请求完全屏蔽，代码抽象程度高，工具调用方便。稳定性强，线上从未出现崩溃。
- 工欲善其事必先利其器，我在zupport库添加日志模块，统一各依赖模块的打印格式，另附我还加了文件操作工具，Check工具，以及一些上层常用逻辑下沉封装。
自驱独立开发，对使用便捷度要求较高，代码稳定无崩溃。(我们组里有统计，崩溃率为0)
Support是一个稍与业务相关，但是相关性并不大的工具能力基础库。全程由我维护。可以被多个java层sdk依赖，使上层实现更加方便简洁。最开始搞这个库的初衷是要写一稳定的http请求类，这种类如果要求低点是很容易实现的，但是我力求将接口封装的足够简单，对调用用户屏蔽了一些sig auth请求逻辑，一些重试逻辑，并运用泛型，将用户回调代码处的处理内容降到很少的程度，直到目前，没有出现一例崩溃。其余的功能，是我在开发其他模块的时候，认为有必要提取公共之处的，都整理至此处。 在模块架构上，尽量做到各司其职，不要有太多重复性代码。目前此库运行良好。


HB Im 最初是我们IM的融合层。我负责后，经历了三个节点，IM融合层拆分重构，  IM 去腾讯化， IM 去融合层和提供新API。
在IM的实现的过程中，我给自己的评价是，一个勤劳的整理师。
这几个节点都涉及到了大需求。第一次重构，当时Sdk中还是存在腾讯Sdk的，我重构的时候，砍了原有大量的if else 结构，搞的策略，统一分散各处的常量类，以及其余比较乱的部分都进行了整理，使代码上看起来更加整洁。等到第二次IM去腾讯化的时候，我这里得以迅速的完成需求，将腾讯涉及的所有快速稳定的删掉。第三个比较大的就是我们砍掉了一个aar包，将代码收回im仓库中，并更新了API的使用方式，支持同个用户去不同的群组发信息。

Zoss库是我们的一个文件上传库，其功能是上传文件到服务端
Zoss目前处于比较前期的阶段，是5月份用时两周紧急研发出来的，因为需求来的太着急，目前底层暂时用的腾讯的能力，但是我在代码的设计与实现上，个人并没有因为紧张的工期而忽略其他环节，例如从方案设计到代码实现，到写打包脚本纳入我们原有的模块管理体系，再到完整的注释，文档输出，并在Demo上实现完整的测试面板，demo上整体打包脚本的编写，所有细节都配套存在，力争所有环节保质保量。
目前Zoss的实现是支持多引擎的，由于一些客观原因，目前借鉴的是腾讯的能力。后期是需要做自研的上传能力的，未来会像我们上半年Im那样，通过逐步迭代完成替换。敬请期待。

对于右侧的这四个部分，时间关系我讲一下重点的来。 
这几个库主要是我在需求中，改上下层涉及到的，比如前些日子由我主牵的API耗时时长统计一二三期实现，有上层到下层都要进行改动，直至我们底层的公共依赖库transport库。比如我们的美颜接入，接入过程中会出现各种问题，我通常会直接review底层实现，去找原因。我之前做过不少这样的需求，时间限制不多说，虽然不是自己负责的库，但是我认为工作中应该尽可能的多了解一些实现细节的，我个人是比较认同去做一个多面手，固守一亩三分地我个人是不赞同的。所以我在工作当中，经常有不有关于自己的都会看看，开发中遇到的问题，也不会因为这不是我维护的就不去看不去做。所以后来我就慢慢的涉及到了更多的库。

## 第二是我们Demo的开发与维护
另外我还主要负责维护我们团队安卓端集成demo的开发与维护功能，目前demo主要来模拟业务端调用流程，实现采用MVVM框架，此demo作为研发集成自测，和我们测试人员测试功能使用，为确保产品质量提供有力支持！
，此demo从设计到开发，都是我们自己完成的，界面可能不及商用界面那么漂亮，但是其操作设计和运行流程的设计，为保障对外提供软件质量提供强力支持。
我们demo目前具有的功能有四点
- RTC 多人会议 & 美颜 用于模拟bosshi流程
- 多人视频 & IM  用于模拟直聘面试间
- 阿丽塔测试 
- 功能丰富的彩蛋盒子，其中彩蛋盒子在原有的集成能力上，增加自研的，运行时信息展示，自定义接口调试，网络测速，RTC万物皆可配能力。方便开发调试代码，以及测试验证一些新增能力。
  
我想在这里说下彩蛋盒子，彩蛋里面的大部分功能是我结合工作中大家遇到的问题，想出来的解决办法，比如里面有个比较值得一提的能力，就是自定义接口测试。写这个的原因是，我发现我们有时候，是需求实现赶在demo之前的，我平时由于自身也维护了较多库，不可能每次都能将demo的版本都更新到最新，假如此时我临时赶工在demo里面加功能测试，很可能会导致代码冗余，因为赶工情况下很有可能向功能妥协，而不能保障代码质量。针对这种情况，我想了一个办法就是，我私加一个可以测试所有接口的入口，这个入口点进去可以读到指定类的所有接口信息，这个接口参数都是可以编辑的，可以运行的，以便于解决紧急情况下，没来的及在demo写功能界面的时候，就要上线。没有入口进行集成测试的问题。

## 第三是对于团队中其他人指导
我工作中尽管也做过支持全客户端种类的需求，但是在我加入团队以来，更多从事的是安卓相关的工作， 我在开发VR的过程中，有些方案例如方向导航器的实现是我自己想出思路并率先进行实现的，在此期间，我执导过IOS负责同样功能同学进行IOS端导航器进行IOS端实现。
另外，我前些日子负责了我们API耗时上报的全端实现。由我主牵。API耗时时长上报是一个比较综合的问题，涉及到Android， IOS， Win， Mac，Web 服务端 六端。 涉及的代码改动仓库不止一个，这是一个比较综合的问题。对此我跟我的小伙伴们针对方案实现进行多次沟通讨论。现在这个功能已经上线了。此功能有利于我们排查未来优化点，有利于我们从1到100进步，找到明确的方向。我对我的自我评价是，综合而平稳！我开发的时候涉及了一些底层代码的改动，从一个人只能开发一端，到逐渐深入底层，一个人开发的逻辑可以运用到多端，是一个进步。从只开发安卓，到从更高的维度考虑全端，又是一个进步。从一亩三分地，到顾全所有人所有模块方面，也是一个进步

# 下面是专业能力与综合素质角度， 我认真解读了T4的职级综述，判定我已经掌握甚至超过以上能力。
第一条，我拿我刚刚提到的文件上传，短短时间内，开发的完整流程，技术方案文档，技术方案一期讨论，二期讨论，新库建立， 代码功能实现，代码单元测试， 代码Demo功能实现， 代码打包脚本整合体系内，API文档，集成文档，等等环节一应具备。而且我在代码设计的时候，为未来我们逐步替换自研文件上传，外部不做改动，采取策略模式，对代码进行封装。代码实现细节并没有因为工期紧而不顾代码结构，我PPT的后几页会附带上代码。这里不做赘述。
第二条，我举得案例是，刚刚提及到的API耗时上报，就可以很好的证明我是符合这条标准的。这个需求我是牵头的，方案也是我拖动实现的，涉及到六端。另外思考模块缺陷方面，在support库的提出，优化IM代码结构等，都是比较符合的。
第三条，Demo改版，彩蛋细节实现，是我主动发现平常我们流程的问题，并找到的一种解决方案。在VR项目的实现中，当第二次业务侧找我改张数的时候，我就意识到，应该把张数的设置交给调用方掌握，我发现了这个问题，但是当时是刚接手VR对代码了解不是很深入，并且在当时的代码实现上讲，实现张数自由设置是一个很复杂的问题，因为当时空间点是写死的，第一排多少张第二排多少张，就这样计算。并且这个点的坐标和我们陀螺仪返回的角度得到的坐标系有很大不同，要做很多转换。这块是比较麻烦的，前期我没有太大的勇气敢改这块，但是这件事我心里一直惦记着，后来随着对代码的逐步了解，我把uikit改成了可以任意调整张数，由外部决定。业务侧之后没有因为这件事情再找过我。我平时工作中也是对这些重复的工作是比较敏感的。通常是能解决的我都会想办法解决。我觉得这个特质为我提高效能，为我能同时维护这么多库且运行平稳省出了不少时间。工作当中，对接人跟我反馈的问题是比较少的。这是一个良好的正反馈。

# 下面我将针对我VR中的需求做一下案例详述：
# 重点案例分享1
全景库，其主要的能力是全景照片的采集，给大家展示一下它是什么，怎么用的。
点视频
这个功能呢主要是用来采集三维空间一圈的照片，这些照片会被存储下来，之后业务侧拿到照片之后会上传到服务端，然后他们进行算法合成，形成一个VR效果的图片。
那通过视频中我们可以看出，如果将这个功能简化到极致，可以这样描述。就是，手机引导用户拍出以他为中心环绕式的照片。
下面我来讲讲我们怎么来实现的。
对需求进行进一步提纯，发现我们实现 1 预览  2 拍照  3 知道用户在什么方位 4拍完环绕式渲染。 如果这四个条件满足，那么我们是可以实现这个能力的。

翻页：
如本图所示，对于预览和拍照而言，我们用Camera2 就可以搞定，之所以采用这个API是因为它具有更高的灵活性，并且我们有超广角拍摄功能，这个功能只能用Camera2调用出来。Camera2可以解决刚才提到的第一点和第二点即预览和拍照能力。
第三点是，我们要知道用户位于什么方位，目前大部分安卓手机内置陀螺仪，并且安卓Sdk已经提供了良好的相关API，我们是可以通过相关API的调用获取陀螺仪参数的。不过陀螺仪返回的参数，Y轴域在 -180 至 180角度，这个在开发导航器的时候是个坑，所以代码中采取了很多取模运算，来解决两点之间夹角过大的问题。
另外我们要解决的追后一点是环绕式渲染的问题，我们从刚才的视频可以看出，要将一张张图片渲染到一个类似于球体的空间上，这种渲染效果可以采用openGl，利用其矩阵变换渲染2D纹理照片实现。OpenGl是一个关于操作图形，图像函数的规范，OpenGl库的开发者通常是显卡的生产商，Android上用到的是OpenGlEs，是OpenGl的精简子集，目前被广泛的应用在智能手机中。在Android中，OpenGl提供了一套GlSurfaceView，和其自身的Render，
而在Camera2中，Api接受一个Surface，每一个Surface中都需要持有一个SurfaceTexture， 其一个重要作用是，在Camera2中，采集到视频帧的时候有相应的回调，并且其持有一个纹理地址，这个地址在Surface初始化之后，Surface可以拿到。这个SurfaceTexture可以由开发者自己去创建，其中有一个构造方法就是接受一个由OpenGl创建的纹理名称，
这样的话， 那么我们反过来理解一下，我们值需要用OpenGl glGenTextures 创建一个纹理，然后用这个纹理生成一个新的SurfaceTexture对象，之后用这个SurfaceTexture对象初始化Surface，然后在调用Camera2 createCaptureSession 方法的时候讲Surface设置进去即可！OpenGl下面的shader，texture，matrix，这三个，在我接下来介绍的实现原理的时候，会提及到，做下补充。

翻页，我们看这里的图片。
我刚刚讲了，我们应该怎么使用Camera2采集数据与OpenGl生成的Texture进行绑定，但是数据为什么会流动到这里呢？这个Texture到底是什么呢？为什么Camera2能识别Opengl创建的纹理呢？纹理是什么概念呢？
首先介绍一下Surface，Surface表示的是一块用于填充图像数据的内存空间，更确切的讲，它指向的是一块屏幕缓冲区!每一个Surface都可以拥有自己的尺寸和数据格式，
而OpenGl中的纹理主要是有两个部分组成，纹理采样状态和包含纹理值的数据缓冲区。前者决定怎么操作数据，后者决定操作哪里的数据。我们在生成纹理之后，代码上便会为纹理生成绑定一个缓冲区，这个缓冲区正是Surface指向的那块缓冲区。
到这里的话，Camera2 就已经知道要将数据存放在何处了，Camera2的API模型被设计成了管道，它按顺序梳理每一帧的请求并将结果返回给客户端，CameraServer中初始化时会起个RequestThread，不断循环等待处理的request。我们在创建Request的时候，同样会将Surface设置进去，等到硬件返回的数据，便会根据Surface中的配置得到处理，并写到缓冲区。这样就形成了闭环。
而我们createCaptureSession， 就是发起一段对话，我们要拿session对象才能发送各种Request。

直到这里，我们已经了解了Camera2 与 Opengl的联通，渲染算是差不多了， 但是我们还要知道手机运动方位。那就是陀螺仪这个硬件。安卓有GyroSensorManager API可供使用，onSensorChanged会不断被回调出来，我们是可以从里面拿到陀螺仪 xyz 三维空间轴上的偏移角度的。由于每个陀螺仪同一个方位返回的角度值不同，所以我们将角度区间进行统一，计算时尽量运用移动产生的差值来计算位置，这块转换在实现需求的时候其实挺费劲的。为此，我们新增了一个PositionManager的管理类，用于梳理照片空间角度排布，对比拍照位置，是否倾斜等等关于位置相关的逻辑。

那么到了这里呢，当视频流我们可以串通了，用户的空间方位我们也掌握了，接下来就是渲染问题
就拿拍照这个流程来讲，当用户拍下一张照片的时候，就意味着这个照片要被贴出去，并且之后随着我们陀螺仪移动，所有贴上去的照片都要移动！我讲一下，拍下照片之后，大致发生了什么。

首先当拍照之后，由于我们之后都要展示刚才拍的照片，其实这个过程不算复杂，生成一个纹理，将纹理与我们最初生成的那段缓冲区，grameBuffer进行绑定， 也就是图中的BindFramebufferAndTexture环节 ，此时缓冲区中的数据便是刚才预览的数据，这个纹理是必须记录下来的，以便于后期旋转的时候做矩阵变换，就像视频中展示的那样，所有已经拍过的图片都会进行旋转。不过当用户刚拍下照片的那一刹那没有涉及到过于复杂的矩阵变换，直接贴到摄像机前方即可。但是当图贴完之后，用户还要移动旋转什么的，原先已经拍好的照片是要跟着我们的移动角度运动的。所以我们要读出之前已经记录好的纹理记录，然后拿到此时手机的旋转方向，计算旋转矩阵，计算完后，便利用我们最初创建好的着色器程序进行渲染，图片就贴上去了。这样讲来看起来并不是很复杂，但是前面我们提到了着色器，这是一个比较重要的点，我接下为大家解释一下着色器是啥，然后怎么用，怎么旋转贴上去的图片。

在OpenGl中，任何事物其实都是在3D空间中的，但是我们的屏幕和窗口却是2D的，这就导致OpenGl需要大量的工作是把3D坐标旋转为适应屏幕的2D像素，3D坐标转为2D坐标的处理过程，是由OpenGl图形渲染管线来管理的，实际上它值得是一堆原始图形数据途径一个输送管道，经过各种变化处理最终出现在屏幕中的过程。它可以被划分为两个主要部分，第一个就是把3D坐标转换为2D坐标，第二个部分是把2D坐标转换为由实际颜色的像素。图形渲染管线接受一组3D坐标，然后把它们转变为你屏幕上的有色2D像素输出。图形渲染管线可以被划分为几个阶段，每个阶段将会把前一个阶段的输出作为输入。所有这些阶段都是高度专门化的（它们都有一个特定的函数），并且很容易并行执行。正是由于它们具有并行执行的特性，当今大多数显卡都有成千上万的小处理核心，它们在GPU上为每一个（渲染管线）阶段运行各自的小程序，从而在图形渲染管线中快速处理你的数据。这些小程序叫做着色器(Shader)。我们看看这张图，其中顶点着色器和片段着色器是我们开发中要用到的。
- 顶点着色器目的是把3D坐标转换为另一种3D坐标。
- 图元装配是将所有的点装配成指定的形状，本图中是一个三角形
- 几何着色器，是把图元形式的一系列顶点作为输入，他可以通过产生新的顶点构造出其他形状，
- 几何着色器的输入会被传入光栅化阶段，他会把图元映射为最终屏幕上的像素，生成供片段着色器使用的片段，在片段着色器运行之前会进行裁切，裁切会丢弃视图以外的所有像素。
- 片段着色器主要目的是计算一个像素的最终颜色，这也是OpenGl所有高级效果产生的地方。

openGl为我们提供了着色器语言，让我们可以手动编写着色器。有图中分别就是操作陀螺仪旋转这种效果的顶点着色器和片段着色器
我们先看看顶点着色器
a_Position 和 a_texCoord 分别是相机照片的顶点，点开下图，它代表的是一个3维空间的点，坐标系是openGl的世界坐标系。虽然写的范围比较大，但是我们将摄像机设置到很远，所以看上去并没有铺满整个屏幕
a_texCoord 这个指的是纹理图片截取坐标，其坐标系是根据纹理图片本身而言的，下图的值代表的是截取图片纹理的全部

然后这块有一个注意的点是，a_texCoord 被赋值给 v_textCoord 作为片段着色器的输入去了，
下面的一个参数，角u_matrix 这个便是我们的矩阵变换。这个参数会在代码中给与设置，稍后会讲
我们看看main函数，对顶点做了矩阵变换。
然后下一行就是赋值而已，以便于值可以被片段着色器拿到。

然后看看片段着色器，
s_texture 指的是一个纹理，这个这个纹理我们会在代码中进行设置。
下面的函数就是，纹理颜色与纹理顶点相对应。取颜色。

翻页：
如下面代码所示，初始化的时候，我们编译了着色器，并生成了对应的着色器程序，我们主要进行修改的是，1 矩阵变换， 2 纹理，所以我们拿到了这个程序中的u_matrix和 s_texture,以便于后期进行设置。
至于Matrix的生成， 我们只是简单的设置的旋转角度，以及摄像机等等，这块不做为重点，只是这个代码是这样实现的。

翻页：
然后关键的是下面这些代码，我们首先会启用着色器程序，重置顶点坐标数据和纹理坐标数据，之后将刚才得到的矩阵数据设置进去，这里的matrixLocation我们在初始化的时候已经给好了。然后同理再设置纹理数据，接下来绘制，应用程序即可，就完成了贴图。
以上是我们贴图的实现关键点

在VR实现导航指示，是一个我个人觉得比较有意思的点。这个涉及到我们将一个三维空间点映射到二维，计算其方向。于是我调研了一些三维转二维的方式，但是效果不是很好，于是我换了一种思路，可以将问题模型简化为一个三角函数相关的几何问题进行解析。
如图所示，这个球中的两个空间点，绿色箭头是用户手机目前对标的空间点，小星星是被建议拍摄的点，那么我们可以简略的将这两个点看做一个矩形，然后求其对角角度的问题。右图是我简化出来的问题模型，我们的数据只能从陀螺仪中得到，所以拿到的值只是Q 在 YZ 面 和 XY面的夹角值， 由于我们模拟的是一个球体，所以Q到任意点的距离是相等的，我们可以利用等腰三角形的一些定理计算得到目标角的大小，推演公式已经给出。核心代码就是图中的这几行，但是还有其他一些比较细节的操作我没有贴上。这个问题的解决方案是由我想出并协助了IOS侧同学进行相同功能的开发，运行效果，指的很准，很顺滑流畅。主要是我在这个需求的开发中感觉自己很机智，印象比较深刻，所以就顺便提以下。

对于VR来讲，我在独立完成每期的需求之外还在里面加了一些自驱研发的功能，比如自定义张数，比如将VR浏览和存储的图片信息改成所见即所得。最开始的时候，业务侧老找我改张数，来测试合成效果，当第二次找我的时候，我就意识到这种问题是影响人效率的问题了，惊觉这种能力应该提供给外部，于是在后期的迭代中，我加上了自定义张数的接口，然后最开始的时候VR拍照的时候走的是ImageReader，调用相机的拍摄流程进行拍照，虽然使用上没什么问题，但是我总觉得来来回回耗时500毫秒还是太慢！于是我改了原本的方案，不用ImageReader拍照流程，直接从openGl中拿数据，并优化了图片的压缩逻辑，效果也是蛮可以的，时间缩到了50ms左右。一加手机。

# 重点案例分享2

正如之前提到的，我除了负责我们的VR全景之外，还全权负责了一些其他的SDK模块。下面我讲下我们的Support库的具体情况。以及选取一个案例来讲。
Support库的定位是我们Android上层的公共依赖库，目前被 demo，rtc, im, 人脸识别认证，全景，和文件上传 6 大模块使用。 其提出的起源是为了解决一个底层的http崩溃问题，我在接到需求的时候发现当时各模块的请求各用各的，而且代码逻辑并没有那么严谨，异常情况下崩溃风险大，于是提出将此类能力封装至一个专门的库中，所有模块均依赖此库，我会不断的在这里添加公共能力，保障稳定性还能提高研发效率。这个建议被采用，我着手进行开发。 目前support库根据现有sdk需要到的能力，抽出来了10个部分，就是下方黄色部分。其中zp-transport 和 zp-matrix是底层打的包。这块由于一些其他原因，不建议做过多拆分于是就妥协加上这两个内容了，对于目前我们对接的业务和需求场景而言没有问题，但是如果接入的业务并没有音视频能力，这两个库便有些多余了，但是目前用到我们SDK的场景均涉及到了音视频，目前而言没什么问题，如果之后业务演进真的到了拆分的时候，我会对这块进行优化。使其更加 简洁。除了这两个库，我封装的统一的日志逻辑，统一了所有模块打印格式，并且，根据我们服务端请求的特点，封装了符合我们请求流程的，能够自请求自维护鉴权信息并完全对外部屏蔽的，并具备多次重试的请求类。另外的一些就是我们的文件操作啊，网络状态，检查参数注解，基础的MVVM和MVP架构以备各模块demo使用，还有一些图片操作，数据格式转换等等一些类。随着各项目的不断发展，我还将进行进一步的整合提炼，目前此库运行良好，自上线以来，我们内部统计的崩溃数据，1例没有！

接下来我对我研发的请求类进行介绍。

翻页
下图是我们原先的代码，在响应回调总做的操作。此代码有一定的缺陷，如果要写的比较严谨的话，是需要不少判断的。代码量就会增加。另外，最开始的时候，我们的每一条请求都是要带鉴权信息的，而且鉴权信息有过期的可能，这种鉴权流程十分通用了已经，我是打算讲这个流程给屏蔽掉，让开发人员直接调用，就尽可能的保障能返回响应的结果。
另外我还要在这个功能里新增重试能力，然后就是我要尽量减少调用者的代码量。

针对减少调用者代码量而言
首先我设计出来的回调接口，是这样的，我想在resPonse中，直接给出泛型的类型，而不是像上张图那样，在回调处再解析一次，然后加各种判断，这种太麻烦，应该尽量减小开发人员的代码量，为此我经过调研，用反射拿到callback正确的泛型信息，利用Gson的解析Api进行解析便完成了这个能力。图中贴出的代码是完成回调类型解析的核心代码。其余的，状态判断，内容判断等其余的复杂判断不做赘述，最终都会在 httpOrStatusCode 和 codeDes中给出错误码和详细描述。我在这个接口的返回里，只要httpOrStatusCode代表成功，返回的泛型所指类型的Bean就恒不为空，可以放心的直接拿来使用。
有时候再复杂的代码，解决核心问题的就这几行，但是请不要因为我图中给的少，就认为此功能so easy，其实实现起来并不是想象的那样，还是挺复杂的。绝知此事要躬行啊。

针对完全屏蔽鉴权信息的请求，和重试逻辑。我最开始的时候是打算在拦截器中作操作，但是后来自己尝试的时候，发现此办法行不通。于是就换了方案。
下图是我现有的实现方案图示：
由此图可以看到，我内部实际上是对okhttp进行了符合我们业务的封装。主要的类是中间这个 ZpOkHttp, 其余的类基本是为了完成ZpOkHttp的能力而设计出来的。ZpOkHttp直接继承自Thread类，原因是我想在里面直接起一个Handler，将用于请求sig auth的信息，以及普通请求的信息加入队列里面去。这个是整个机制运转起来的核心
当代码第一次被调用发起请求的时候，首先会检索内部有无正确的sigAuth，如果没有，直接在队头添加一个sig auth相关的请求，之后再添加刚才被发起的这条请求。等到sig auth 请求完之后，代码会记录当前的sig auth。之后执行刚才发起的那条请求，会将此 信息进行赋值，接下来便正常执行请求逻辑。
当出现请求着的过程中恰好服务端检测鉴权信息过期的时候，我们会在相应里面得到相应的错误码，如果正好是鉴权失败的那几个相关的错误码，便会暂时将这条失败的请求信息记录下来， 在队列头部插入sig auth请求信息，然后再与后面插入这条请求失败的信息。
对于重试， 无论是请求 sig auth 失败，还是普通请求失败，当然这种失败是超时相关的失败，其余的失败问题也没有什么意义。 代码内部都会自动尝试重试，当然重试的核心依然是操作队列。这样逻辑就形成了闭环。

我们看看这个类，ZpOkHttp是这套逻辑的核心类，它内部持有一个ReasyOkHttp变量，这个ReasyOkHttp是我封装的纯工具类，不带任何业务性质。我不想对外暴漏这个类，因为目前没有必要。所以目前这个类的访问域是包访问权限，外部包不可访问。然后下面的SigBean ZpOkHttp的一个静态类，里面记录了sig  auth参数，这个参数，外部可以进行设置赋值。 
RequestInfo 是我用在队列中的数据结构，里面带有用户请求时设置的callback，请求信息，重试次数，和上一次进行请求的结果。因为有个细节是，代码重复请求了3次之后，如果还是失败，就不再重试了，会将上次失败的结果原封返回。这种情况包含两种， 1是 sig auth 接连请求失败，导致一直没有正确的sig auth 可供使用，这种情况下，会将服务端的错误码透出，调用方是可以知道错误原因的。2是这条请求因为网络啊，等问题导致的失败。最终重试次数达到也会返回出去。

翻页
以下是我上述讲述的机制的核心代码，
代码可以看出，每来一个请求，我都会判断是不是sig auth已经过期诸如此类的问题，如果是的话，我便会发一条请求sig auth的message，加入到队列的头，另外原先的那条老消息也会加入到队列的后方。这样就完成了自动请求，和自动重试，外部不会感知。

翻页：
我分享的最后一个案例是关于Demo的，是自定义接口编辑，和接口测试功能。界面如下，有点丑哈。我们组没有专门的UI，并且这个功能是我发现我们团队工作中任何人没有办法避免的一些问题，而想出来的一种解决方案。就像我之前讲的那样，我是Demo的主要开发人员，但是我同时还维护着其余四个SDK，Sdk的开发在我的工作当中优先级是要比demo高的，有时候由于开发工期的限制，我偶尔会出现开发完SDK之后马上邻近提测日期，demo无暇补充用例实现，当然，任何用例我之后都会认真负责的实现，这点从没有落掉过。而且有时候同事们开发的功能也要在demo上进行集成回归，他们如果改代码，成本会比我高，因为还要研究我的代码。不现实。我很早就察觉到这种难以避免的问题了，于是就想，如果紧急情况下，我们能编辑测试接口，进行测试，就好了。由于它位于彩蛋盒子内，是一个内置的功能，所以我就自发实现了这个功能。
虽然界面丑但是使用起来很香，这个是我领导表扬过的功能，在他提出相关流程问题的时候我就已经开发完了，记得有一次跟外部对接开会，要看看设置预览缩放大小的效果，我们之前设计的界面中没有这个功能的UI入口，我临时编辑了一下，就可以了。很方便。我在这里想要突出的是我的自驱力，和执行力哈。
这是一个自定义接口编辑的界面，我们可以通过界面选择要进行测试的类对象，编辑界面会读出相关类的信息，和方法名字，选择完之后会列出方法参数名字，并引导用户进行填写，另外，我在界面中给到了几个比较常用的运行时变量，编辑的时候可以自行选择。对于稍微复杂的对象参数，有json内容填充项可供使用。我梳理我们的SDK，每个API的参数结构是很简单的，用到这种的情况不多。

这个功能的其用途有两个， 
1 用于解决我们开发流程中，demo研发速度赶不上Sdk研发速度，用于迅速集成自测使用
2 用于模拟点击界面相关的自动化测试，来暴漏乱序调用，不合规参数调用情况下，程序的健壮性。

翻页
下面看这张图，这是一个json数据，里面记录了我们想要测试的一些内置用例，代码在执行的时候，会优先读取内置用例信息，如果开发人员觉得操作界面编辑入口比较麻烦，其实是可以在这个脚本中添加用例信息进行测试的。从图中的内容也可以看出，我记录的信息有几个很重要的，就是类名信息，方法名称和方法参数，其中参数中也记录了类名信息，我在执行的时候会解析这些参数，用反射的方式去执行相关方法。

我在界面开启的时候首先会从这个文件中读一些信息，另外去找在沙盒中已经存储的同类文件进行读取，进行接口测试信息的整合，然后再在列表进行展示。这个列表我在PPT中没有给出，列表右下方会有一个加号，点击加号就进行接口信息编辑了， 就是我们前两张图看到的编辑界面。在编辑界面中，界面展示所需要的信息都是反射获取的。我认为毕竟是一个测试功能，反射虽然有时候比较慢，但是这种情况下要求不是很高，所以这就够了。
下面是我核心部分的代码，
翻页 21
不难，这块就是根据类名获取其下的方法名，然后在接口编辑界面当我们选择了一个类之后，便会展示这个类下的所有方法名，以便于我们选择。
第二张图片是前一张PPT的json内容映射出来的数据结构，这个结构会用于测试接口的展示，然后用户点击的时候，便会读取数据中的信息，然后利用反射执行相关的逻辑。这里有类型，方法名，方法参数，这些信息足够使用了。

翻页 22
接下来是用户点击执行测试之后， 对应的对象就应当调用某些方法进行执行，以下是重点代码，即获取被执行对象，使对象执行方法。
第二张图就是获取相关方法的逻辑，这块逻辑比较多，我只截取了一部分。首先是找出同名方法，然后再比较方法参数，最终找出目标方法。
翻页 23
这块便是我们找到最终的方法的执行逻辑。到此，自定义接口测试功能的核心代码讲完了。

这块其实在难度上并不复杂，我讲这块，只是来讲解我面对我所看到的问题，是如何思考如何执行的，我热衷于为提高工作效率做一些额外的付出，我坚信磨刀不误砍柴工，我平常为了保证代码质量，除了严格自测，还会捋着日志看逻辑走的是不是预期的效果，我虽然维护的库不少，但是对接的同事找我反馈的问题不多，以至于我不仅能维护好手头的工作，还有时间去扩展深入其余模块的开发。我认为就自驱力和发现问题解决问题的能力而言，我还是蛮可以的。现在我接的需求，涵盖各大模块，最近也做了一些底层的逻辑，三端均适用，我在这里由衷的感谢我领导对我的栽培，我相信随着我未来接触的项目越来越多和对底层的逐渐深入，我持续学习更多的知识，将自己的优点继续发挥，为团队解决更多有意义的问题，发挥出更大的价值。

最后，感谢各位耐心的听我的讲解。我的演讲结束了。

// 延时是多少
// 超时是多少 2秒
// 这类参数需要做一下功课。
<!-- 你对泛型的了解 -->
Handelr原理
反射原理

